{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Excercise - Creating our own custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This is a notebook that provides a quick overview of how to create your own custom model. You will be creating a simple model.\n",
        "You will be utilizing Keras and Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Water Quality Dataset\n",
        "\n",
        "This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
        "\n",
        "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CPbSYW1U1mfn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvnx0_dT3JEq",
        "outputId": "e2a49c80-09aa-41d0-bdd5-304aff648b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset shape: (3276, 10)\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n",
            "None\n",
            "\n",
            "Target distribution:\n",
            "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
            "0          NaN  204.890455  20791.318981     7.300212  368.516441   \n",
            "1     3.716080  129.422921  18630.057858     6.635246         NaN   \n",
            "2     8.099124  224.236259  19909.541732     9.275884         NaN   \n",
            "3     8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
            "4     9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
            "...        ...         ...           ...          ...         ...   \n",
            "3271  4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
            "3272  7.808856  193.553212  17329.802160     8.061362         NaN   \n",
            "3273  9.419510  175.762646  33155.578218     7.350233         NaN   \n",
            "3274  5.126763  230.603758  11983.869376     6.303357         NaN   \n",
            "3275  7.874671  195.102299  17404.177061     7.509306         NaN   \n",
            "\n",
            "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
            "0       564.308654       10.379783        86.990970   2.963135           0  \n",
            "1       592.885359       15.180013        56.329076   4.500656           0  \n",
            "2       418.606213       16.868637        66.420093   3.055934           0  \n",
            "3       363.266516       18.436524       100.341674   4.628771           0  \n",
            "4       398.410813       11.558279        31.997993   4.075075           0  \n",
            "...            ...             ...              ...        ...         ...  \n",
            "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
            "3272    392.449580       19.903225              NaN   2.798243           1  \n",
            "3273    432.044783       11.039070        69.845400   3.298875           1  \n",
            "3274    402.883113       11.168946        77.488213   4.708658           1  \n",
            "3275    327.459760       16.140368        78.698446   2.309149           1  \n",
            "\n",
            "[3276 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('water_potability.csv')\n",
        "\n",
        "print(\"Dataset shape:\", data.shape)\n",
        "print(\"\\nDataset info:\")\n",
        "print(data.info())\n",
        "print(\"\\nTarget distribution:\")\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaWE9xKb-MhD"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "233HdERE96ID",
        "outputId": "3d7169fb-df1f-46a3-93e0-db57f70c75cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values before preprocessing:\n",
            "ph                 491\n",
            "Hardness             0\n",
            "Solids               0\n",
            "Chloramines          0\n",
            "Sulfate            781\n",
            "Conductivity         0\n",
            "Organic_carbon       0\n",
            "Trihalomethanes    162\n",
            "Turbidity            0\n",
            "Potability           0\n",
            "dtype: int64\n",
            "\n",
            "Missing values after preprocessing:\n",
            "ph                 0\n",
            "Hardness           0\n",
            "Solids             0\n",
            "Chloramines        0\n",
            "Sulfate            0\n",
            "Conductivity       0\n",
            "Organic_carbon     0\n",
            "Trihalomethanes    0\n",
            "Turbidity          0\n",
            "Potability         0\n",
            "dtype: int64\n",
            "\n",
            "Features shape: (3276, 9)\n",
            "Target shape: (3276,)\n",
            "\n",
            "Features have been scaled using StandardScaler\n"
          ]
        }
      ],
      "source": [
        "# data.fillna(data.mean(), inplace=True)\n",
        "# X = data.drop(\"Potability\", axis=1)\n",
        "# y = data[\"Potability\"]\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Missing values before preprocessing:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "print(\"\\nMissing values after preprocessing:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Split dataset into features (X) and target labels (Y)\n",
        "X = data.drop(\"Potability\", axis=1)\n",
        "y = data[\"Potability\"]\n",
        "\n",
        "print(f\"\\nFeatures shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"\\nFeatures have been scaled using StandardScaler\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfR0r8cGVU7"
      },
      "source": [
        "Plot the Data Appropriately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfSk1lXRYjrh",
        "outputId": "ad676660-ba7a-4320-bf82-e02ec9de0b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 2293 samples (70.0%)\n",
            "Validation set size: 491 samples (15.0%)\n",
            "Test set size: 492 samples (15.0%)\n",
            "\n",
            "Training set shape: (2293, 9)\n",
            "Validation set shape: (491, 9)\n",
            "Test set shape: (492, 9)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# #from sklearn import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# First split: 70% train, 30% temp\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.30, random_state=42)\n",
        "\n",
        "# Second split: Split the 30% temp into 15% validation and 15% test\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {len(X_train)} samples ({len(X_train)/len(X_scaled)*100:.1f}%)\")\n",
        "print(f\"Validation set size: {len(X_val)} samples ({len(X_val)/len(X_scaled)*100:.1f}%)\")\n",
        "print(f\"Test set size: {len(X_test)} samples ({len(X_test)/len(X_scaled)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvjIHLrcGhzc"
      },
      "source": [
        "# Each Memeber Defines their model Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FLwYoJG9jvDa"
      },
      "outputs": [],
      "source": [
        "def benitha():\n",
        "    \"\"\"\n",
        "    Creates a neural network model for water quality classification with specified hyperparameters:\n",
        "\n",
        "    HYPERPARAMETER CHOICES:\n",
        "    - Regularization: L2 (0.01) - Prevents overfitting by penalizing large weights\n",
        "    - Optimizer: Adam with learning rate 0.0005 - Conservative learning rate for stable convergence\n",
        "    - Loss: binary_crossentropy - Appropriate for binary classification\n",
        "    - Metrics: accuracy - Standard metric for classification problems\n",
        "    - Dropout: 0.3 - 30% dropout rate for regularization without being too aggressive\n",
        "    - Architecture: 64->32->16->1 neurons - Decreasing layer sizes for feature extraction\n",
        "    \"\"\"\n",
        "\n",
        "    # Get input shape from the features (9 features in water quality dataset)\n",
        "    input_shape = X_train.shape[1]\n",
        "\n",
        "    # Build the neural network architecture\n",
        "    model = keras.Sequential([\n",
        "        # Input layer\n",
        "        layers.Dense(64,\n",
        "                    activation='relu',\n",
        "                    input_shape=(input_shape,),\n",
        "                    kernel_regularizer=l2(0.01),\n",
        "                    name='hidden_layer_1'),\n",
        "\n",
        "        # Dropout for regularization\n",
        "        layers.Dropout(0.3, name='dropout_1'),\n",
        "\n",
        "        # Second hidden layer\n",
        "        layers.Dense(32,\n",
        "                    activation='relu',\n",
        "                    kernel_regularizer=l2(0.01),\n",
        "                    name='hidden_layer_2'),\n",
        "\n",
        "        # Dropout for regularization\n",
        "        layers.Dropout(0.3, name='dropout_2'),\n",
        "\n",
        "        # Third hidden layer\n",
        "        layers.Dense(16,\n",
        "                    activation='relu',\n",
        "                    kernel_regularizer=l2(0.01),\n",
        "                    name='hidden_layer_3'),\n",
        "\n",
        "        # Output layer for binary classification (potable vs non-potable)\n",
        "        layers.Dense(1, activation='sigmoid', name='output_layer')\n",
        "    ])\n",
        "\n",
        "    # Compile the model with specified hyperparameters\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmWIUNw0-l0y",
        "outputId": "e46d959f-2408-49a3-d54d-7744277d00a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BENITHA'S HYPERPARAMETER CHOICES AND JUSTIFICATIONS:\n",
            "============================================================\n",
            "1. REGULARIZATION - L2 (coefficient: 0.01):\n",
            "   - Chosen to prevent overfitting by adding penalty for large weights\n",
            "   - L2 regularization creates smoother decision boundaries\n",
            "   - Coefficient 0.01 provides moderate regularization without being too restrictive\n",
            "\n",
            "2. OPTIMIZER - Adam (learning_rate: 0.0005):\n",
            "   - Adam combines benefits of AdaGrad and RMSProp with momentum\n",
            "   - Learning rate 0.0005 is conservative (lower than default 0.001)\n",
            "   - Ensures stable convergence without overshooting optimal weights\n",
            "\n",
            "3. DROPOUT RATE - 0.3:\n",
            "   - 30% dropout rate provides effective regularization\n",
            "   - Not too aggressive (like 0.5) which could harm learning\n",
            "   - Applied after each hidden layer for consistent regularization\n",
            "\n",
            "4. EARLY STOPPING PARAMETERS:\n",
            "   - Monitor: 'val_loss' - Stops training when validation loss stops improving\n",
            "   - Patience: 10 - Allows 10 epochs without improvement before stopping\n",
            "   - Min_delta: 0.001 - Only improvements >0.001 are considered significant\n",
            "   - This prevents overfitting and saves computational resources\n"
          ]
        }
      ],
      "source": [
        "print(\"BENITHA'S HYPERPARAMETER CHOICES AND JUSTIFICATIONS:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. REGULARIZATION - L2 (coefficient: 0.01):\")\n",
        "print(\"   - Chosen to prevent overfitting by adding penalty for large weights\")\n",
        "print(\"   - L2 regularization creates smoother decision boundaries\")\n",
        "print(\"   - Coefficient 0.01 provides moderate regularization without being too restrictive\")\n",
        "\n",
        "print(\"\\n2. OPTIMIZER - Adam (learning_rate: 0.0005):\")\n",
        "print(\"   - Adam combines benefits of AdaGrad and RMSProp with momentum\")\n",
        "print(\"   - Learning rate 0.0005 is conservative (lower than default 0.001)\")\n",
        "print(\"   - Ensures stable convergence without overshooting optimal weights\")\n",
        "\n",
        "print(\"\\n3. DROPOUT RATE - 0.3:\")\n",
        "print(\"   - 30% dropout rate provides effective regularization\")\n",
        "print(\"   - Not too aggressive (like 0.5) which could harm learning\")\n",
        "print(\"   - Applied after each hidden layer for consistent regularization\")\n",
        "\n",
        "print(\"\\n4. EARLY STOPPING PARAMETERS:\")\n",
        "print(\"   - Monitor: 'val_loss' - Stops training when validation loss stops improving\")\n",
        "print(\"   - Patience: 10 - Allows 10 epochs without improvement before stopping\")\n",
        "print(\"   - Min_delta: 0.001 - Only improvements >0.001 are considered significant\")\n",
        "print(\"   - This prevents overfitting and saves computational resources\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDSPmAB9jkrG"
      },
      "source": [
        "# Start the training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OWQHapf3jlYH",
        "outputId": "0204ed55-fe0f-4235-9d62-b0f3db88624d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL ARCHITECTURE:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_3 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,265</span> (12.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,265\u001b[0m (12.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,265</span> (12.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,265\u001b[0m (12.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting model training...\n",
            "Epoch 1/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4945 - loss: 1.4596 - val_accuracy: 0.6314 - val_loss: 1.1980\n",
            "Epoch 2/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6006 - loss: 1.1582 - val_accuracy: 0.6314 - val_loss: 0.9994\n",
            "Epoch 3/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6155 - loss: 0.9759 - val_accuracy: 0.6334 - val_loss: 0.8715\n",
            "Epoch 4/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6348 - loss: 0.8535 - val_accuracy: 0.6354 - val_loss: 0.7925\n",
            "Epoch 5/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6160 - loss: 0.7926 - val_accuracy: 0.6436 - val_loss: 0.7429\n",
            "Epoch 6/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6018 - loss: 0.7522 - val_accuracy: 0.6415 - val_loss: 0.7106\n",
            "Epoch 7/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6297 - loss: 0.7142 - val_accuracy: 0.6456 - val_loss: 0.6902\n",
            "Epoch 8/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6224 - loss: 0.7003 - val_accuracy: 0.6538 - val_loss: 0.6767\n",
            "Epoch 9/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6511 - loss: 0.6802 - val_accuracy: 0.6619 - val_loss: 0.6638\n",
            "Epoch 10/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6206 - loss: 0.6858 - val_accuracy: 0.6640 - val_loss: 0.6567\n",
            "Epoch 11/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6398 - loss: 0.6787 - val_accuracy: 0.6619 - val_loss: 0.6500\n",
            "Epoch 12/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6734 - loss: 0.6533 - val_accuracy: 0.6680 - val_loss: 0.6472\n",
            "Epoch 13/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6630 - loss: 0.6644 - val_accuracy: 0.6741 - val_loss: 0.6424\n",
            "Epoch 14/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6385 - loss: 0.6686 - val_accuracy: 0.6904 - val_loss: 0.6389\n",
            "Epoch 15/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6493 - loss: 0.6660 - val_accuracy: 0.6843 - val_loss: 0.6362\n",
            "Epoch 16/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 0.6533 - val_accuracy: 0.7026 - val_loss: 0.6368\n",
            "Epoch 17/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6558 - loss: 0.6546 - val_accuracy: 0.6904 - val_loss: 0.6344\n",
            "Epoch 18/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6578 - loss: 0.6573 - val_accuracy: 0.6741 - val_loss: 0.6336\n",
            "Epoch 19/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6627 - loss: 0.6546 - val_accuracy: 0.6986 - val_loss: 0.6340\n",
            "Epoch 20/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.6524 - val_accuracy: 0.6884 - val_loss: 0.6323\n",
            "Epoch 21/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6675 - loss: 0.6533 - val_accuracy: 0.6782 - val_loss: 0.6320\n",
            "Epoch 22/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6662 - loss: 0.6600 - val_accuracy: 0.6904 - val_loss: 0.6270\n",
            "Epoch 23/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6518 - loss: 0.6559 - val_accuracy: 0.6782 - val_loss: 0.6302\n",
            "Epoch 24/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6738 - loss: 0.6419 - val_accuracy: 0.7006 - val_loss: 0.6299\n",
            "Epoch 25/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6851 - loss: 0.6446 - val_accuracy: 0.6823 - val_loss: 0.6292\n",
            "Epoch 26/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6665 - loss: 0.6429 - val_accuracy: 0.6965 - val_loss: 0.6304\n",
            "Epoch 27/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6765 - loss: 0.6456 - val_accuracy: 0.6802 - val_loss: 0.6277\n",
            "Epoch 28/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6551 - loss: 0.6633 - val_accuracy: 0.6823 - val_loss: 0.6267\n",
            "Epoch 29/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6787 - loss: 0.6425 - val_accuracy: 0.6843 - val_loss: 0.6277\n",
            "Epoch 30/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6548 - loss: 0.6544 - val_accuracy: 0.6864 - val_loss: 0.6267\n",
            "Epoch 31/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6720 - loss: 0.6439 - val_accuracy: 0.6945 - val_loss: 0.6258\n",
            "Epoch 32/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6881 - loss: 0.6384 - val_accuracy: 0.6925 - val_loss: 0.6251\n",
            "Epoch 33/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6531 - loss: 0.6550 - val_accuracy: 0.6741 - val_loss: 0.6270\n",
            "Epoch 34/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6844 - loss: 0.6386 - val_accuracy: 0.6945 - val_loss: 0.6265\n",
            "Epoch 35/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6815 - loss: 0.6379 - val_accuracy: 0.6904 - val_loss: 0.6264\n",
            "Epoch 36/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6652 - loss: 0.6542 - val_accuracy: 0.6802 - val_loss: 0.6266\n",
            "Epoch 37/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6830 - loss: 0.6348 - val_accuracy: 0.6823 - val_loss: 0.6266\n",
            "Epoch 38/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6655 - loss: 0.6448 - val_accuracy: 0.6864 - val_loss: 0.6235\n",
            "Epoch 39/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6645 - loss: 0.6477 - val_accuracy: 0.6741 - val_loss: 0.6249\n",
            "Epoch 40/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6751 - loss: 0.6363 - val_accuracy: 0.7006 - val_loss: 0.6253\n",
            "Epoch 41/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6778 - loss: 0.6333 - val_accuracy: 0.6925 - val_loss: 0.6270\n",
            "Epoch 42/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6565 - loss: 0.6557 - val_accuracy: 0.6986 - val_loss: 0.6260\n",
            "Epoch 43/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6702 - loss: 0.6473 - val_accuracy: 0.6904 - val_loss: 0.6251\n",
            "Epoch 44/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6644 - loss: 0.6389 - val_accuracy: 0.6864 - val_loss: 0.6248\n",
            "Epoch 45/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6597 - loss: 0.6480 - val_accuracy: 0.6864 - val_loss: 0.6240\n",
            "Epoch 46/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6617 - loss: 0.6520 - val_accuracy: 0.6843 - val_loss: 0.6223\n",
            "Epoch 47/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.6388 - val_accuracy: 0.6802 - val_loss: 0.6245\n",
            "Epoch 48/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6635 - loss: 0.6546 - val_accuracy: 0.6782 - val_loss: 0.6285\n",
            "Epoch 49/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6578 - loss: 0.6511 - val_accuracy: 0.6925 - val_loss: 0.6215\n",
            "Epoch 50/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6687 - loss: 0.6463 - val_accuracy: 0.6782 - val_loss: 0.6231\n",
            "Epoch 51/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6841 - loss: 0.6401 - val_accuracy: 0.6925 - val_loss: 0.6277\n",
            "Epoch 52/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6730 - loss: 0.6409 - val_accuracy: 0.6843 - val_loss: 0.6237\n",
            "Epoch 53/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6618 - loss: 0.6508 - val_accuracy: 0.6904 - val_loss: 0.6257\n",
            "Epoch 54/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6775 - loss: 0.6392 - val_accuracy: 0.6864 - val_loss: 0.6240\n",
            "Epoch 55/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6510 - loss: 0.6571 - val_accuracy: 0.6925 - val_loss: 0.6233\n",
            "Epoch 56/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6632 - loss: 0.6463 - val_accuracy: 0.6925 - val_loss: 0.6212\n",
            "Epoch 57/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6749 - loss: 0.6401 - val_accuracy: 0.6864 - val_loss: 0.6236\n",
            "Epoch 58/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6690 - loss: 0.6441 - val_accuracy: 0.6823 - val_loss: 0.6226\n",
            "Epoch 59/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6773 - loss: 0.6308 - val_accuracy: 0.6843 - val_loss: 0.6373\n",
            "Epoch 60/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6815 - loss: 0.6424 - val_accuracy: 0.6843 - val_loss: 0.6241\n",
            "Epoch 61/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6695 - loss: 0.6443 - val_accuracy: 0.6864 - val_loss: 0.6262\n",
            "Epoch 62/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6944 - loss: 0.6296 - val_accuracy: 0.6884 - val_loss: 0.6275\n",
            "Epoch 63/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6633 - loss: 0.6537 - val_accuracy: 0.6823 - val_loss: 0.6256\n",
            "Epoch 64/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6761 - loss: 0.6300 - val_accuracy: 0.6904 - val_loss: 0.6231\n",
            "Epoch 65/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6557 - loss: 0.6517 - val_accuracy: 0.6823 - val_loss: 0.6236\n",
            "Epoch 66/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6753 - loss: 0.6375 - val_accuracy: 0.6721 - val_loss: 0.6242\n",
            "Epoch 66: early stopping\n",
            "Restoring model weights from the end of the best epoch: 56.\n",
            "\n",
            "Training completed after 66 epochs\n"
          ]
        }
      ],
      "source": [
        "# Create the model\n",
        "model = benitha()\n",
        "\n",
        "# Display model architecture\n",
        "print(\"MODEL ARCHITECTURE:\")\n",
        "model.summary()\n",
        "\n",
        "# Define early stopping callback with specified parameters\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nStarting model training...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining completed after {len(history.history['loss'])} epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1trEQPGFfxQZ",
        "outputId": "833bb689-e1b1-4d95-f9a8-6818b190dbc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.688, Validation Accuracy: 0.692, Test Accuracy: 0.693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "==================================================\n",
            "FINAL MODEL PERFORMANCE METRICS\n",
            "==================================================\n",
            "Test Accuracy: 0.6931\n",
            "Test Loss: 0.6306\n",
            "F1 Score: 0.4215\n",
            "Precision: 0.7237\n",
            "Recall: 0.2973\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model\n",
        "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train Accuracy: %.3f, Validation Accuracy: %.3f, Test Accuracy: %.3f' % (train_acc, val_acc, test_acc))\n",
        "\n",
        "# Get predictions for test set to calculate additional metrics\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Calculate F1, Precision, and Recall\n",
        "f1 = f1_score(y_test, y_pred_binary)\n",
        "precision = precision_score(y_test, y_pred_binary)\n",
        "recall = recall_score(y_test, y_pred_binary)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"FINAL MODEL PERFORMANCE METRICS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "XH_V-e-Ff5q2",
        "outputId": "85b6024a-ac15-419c-b493-a88d95606bb0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training history\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
